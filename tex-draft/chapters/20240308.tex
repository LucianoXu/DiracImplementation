\chapter{20240308}

\newcommand*{\unit}{\texttt{unit}}
\newcommand*{\utt}{\texttt{tt}}
\newcommand*{\fst}{\texttt{fst}}
\newcommand*{\snd}{\texttt{snd}}
\newcommand*{\reduce}{\ \triangleright\ }
\newcommand*{\reducefrom}{\ \triangleleft\ }

\newcommand*{\zeroK}[1]{\mathbf{0}_{\mathcal{K}(#1)}}
\newcommand*{\zeroB}[1]{\mathbf{0}_{\mathcal{B}(#1)}}
\newcommand*{\zeroO}[1]{\mathbf{0}_{\mathcal{O}(#1)}}


\section{Core Language: DN}

The core language DN consists of limited symbols for Dirac notation, and its term rewriting system is expressed in standard AC-rewriting with congruence proved.

\begin{definition} [atomic basis signature]
  The \textbf{atomic basis signature} $\Sigma_\mathcal{B}$ is an arbitrary signature.
\end{definition}

\begin{definition} [complex scalar signature]
  The \textbf{complex scalar signature} $\Sigma_\mathcal{S}$ contains constant symbols $0, 1, \text{Â½}$, a unary symbol $*$ and binary symbols $+, \times$.
\end{definition}

\begin{definition}[language of Dirac Notation]
  The \textbf{language of Dirac Notation}, denoted as $\mathfrak{DN}(\Sigma_\mathcal{B}, \Sigma_\mathcal{S})$, has five sorts defined as follows:
  \begin{align*}
    & \mathcal{A} \textrm{(base)} && t ::= && x\ |\ b\ |\ (t, t)\ |\ \fst\ t\ |\ \snd\ t \\
    & \mathcal{S} \textrm{(scalar)} && S ::= && x\ |\ C(\alpha)\ |\ \delta_{t, t}\ |\ S + S\ |\ S \times S\ |\ S^*\ |\ B \cdot K \\
    & \mathcal{D} \textrm{(Dirac notation)} && D ::= && x\ |\ \mathbf{0}\ |\ D^\dagger\ |\ S.D\ |\ D + D \\
    & && && |\ \ket{s}\ |\ D \cdot_{K} D\ |\ D \otimes_{K} D \\
    & && && |\ \bra{s}\ |\ D \cdot_{B} D\ |\ D \otimes_{B} D \\
    & && && |\ \mathbf{1}_\mathcal{O}\ |\ D \otimes_P D\ |\ D \cdot_{O} D\ |\ D \otimes_{O} D
  \end{align*}
  Here $x$ is a variable, $b$ is a term of $\Sigma_\mathcal{B}$ and $\alpha$ is a term of $\Sigma_\mathcal{S}$.

\end{definition}

\textbf{Remark: } Although we use the same symbol in different sorts ($B \cdot K$ and $O \cdot K$, for example), they are actually different funtions and can be easily distinguished by the context. This is also reflected in the \texttt{CiME} script.


\yx{I encountered some confluence problem for conjugate and transpose, and the natural solution is to consider them as a whole ($\dagger$), which is also more common in quantum computing.}


\subsection{Dirac Notation Algebra}

With the language $\mathfrak{DN}(\Sigma_\mathcal{B}, \Sigma_\mathcal{S})$, we want to define when two terms are equal. This is described by an algebra with axioms.

\yx{I didn't notice such a formal definition of Dirac notation algebra anywhere, so I came up with one from the TRS below.}

\yx{This should imply the axioms of the vector space in Lineal.}

\begin{align*}
  \fst\ (s, t) = s \\
  \snd\ (s, t) = t \\
  (\fst\ s, \snd\ s) = s \\
  \\
  C(\alpha) + C(\beta) = C(\alpha + \beta) \\
  C(\alpha) \times C(\beta) = C(\alpha \times \beta) \\
  C(\alpha)^* = C(\alpha^*) \\
  C(0) + a = a \\
  C(0) \times a = C(0) \\
  C(1) \times a = a \\
  a \times (b + c) = a \times b + a \times c \\
  \delta_{s, t}^* = \delta_{s, t} \\
  (a + b)^* = a^* + b^* \\
  (a \times b)^* = a^* \times b^* \\
  (a^*)^* = a \\
  (B \cdot K)^* = K^\dagger \cdot B^\dagger \\
  \vdots \\
  B \cdot (O \cdot K) = (B \cdot O) \cdot K \\
  (O_1 \otimes O_2) \cdot (K_1 \otimes K_2) = (O_1 \cdot K_1) \otimes (O_2 \cdot K_2)
\end{align*}

\yx{Do we really need such an algebra? It seems that the algebra will not be much simpler than the TRS.}


\subsection{Semantics}
Constructed in CoqQ.

\subsection{Module Theories}

We want to study the theory of Dirac notations modulo the scalars and classical basis. This idea is inspired by the Lineal paper \cite{Arrighi2017}.

\begin{definition}[complex scalar rewrite system]
  A \textbf{complex scalar rewrite system} is a rewrite system $\mathfrak{S}$ for $\Sigma_\mathcal{S}$ such that:
  \begin{itemize}
    \item $\mathfrak{S}$ is terminating and ground confluent,
    \item $+$ and $\times$ are AC-symbols,
    \item for all closed terms $\alpha$, $\beta$ and $\gamma$, the pair of terms
      \begin{itemize}
        \item $0 + \alpha$ and $\alpha$
        \item $0 \times \alpha$ and $0$,
        \item $1 \times \alpha$ and $\alpha$,
        \item $\alpha \times (\beta + \gamma)$ and $\alpha \times \beta + \alpha \times \gamma$,
        \item $(\alpha + \beta)^*$ and $\alpha^* + \beta^*$,
        \item $(\alpha \times \beta)^*$ and $\alpha^* \times \beta^*$,
        \item $(\alpha^*)^*$ and $\alpha$,
      \end{itemize}
      have the same normal forms,
    \item $0$ and $1$ are normal terms.
  \end{itemize}
\end{definition}


\begin{definition}[atomic basis rewrite system]
  An \textbf{atomic basis rewrite system} $\mathfrak{B}$ is a terminating and ground confluent rewrite system for $\Sigma_\mathcal{B}$.
\end{definition}


\subsection{TRS for DN}
\label{sec: typed_dirac_rules}

\begin{definition} [TRS $\mathfrak{DN}$]
  The AC-rewrite system $\mathfrak{DN}$ conssits of all the rules in Sec.\ref{sec: typed_dirac_rules}.
  The AC-symbols are $+$ (for all sorts) and $\times$. The commutative symbol is $\delta_{s, t}$.
\end{definition}

\subsubsection*{\textsf{BASIS}}
\begin{align*}
    \vdash \fst\ (e_1, e_2) \reduce e_1
    \qquad
    \vdash \snd\ (e_1, e_2) \reduce e_2
    \qquad
    \vdash (\fst\ e, \snd\ e)\reduce e
\end{align*}

\subsubsection*{\textsf{DELTA}}
\begin{align*}
  & \vdash \delta_{u, (s, t)} \reduce \delta_{\fst\ u, s} \times \delta_{\snd\ u, t} \\
  & \vdash \delta_{\fst\ u, \fst\ v}\times\delta_{\snd\ u, \snd\ v} \reduce \delta_{u, v}
\end{align*}

\textbf{Remark: } These rules are for completion.


\subsubsection*{\textsf{SCR-COP}}
\begin{align*}
  & \vdash C(0) + S \reduce S \\
  & \vdash C(\alpha) + C(\beta) \reduce C(\alpha + \beta) \\
  & \vdash S + S \reduce C(1 + 1) \times S \\
  & \vdash C(\alpha) \times S + S \reduce C(\alpha + 1) \times S \\
  & \vdash C(\alpha) \times S + C(\beta) \times S \reduce C(\alpha + \beta) \times S
  \\
  \\
  & \vdash C(0) \times S \reduce C(0) \\
  & \vdash C(1) \times S \reduce S \\
  & \vdash C(\alpha) \times C(\beta) \reduce C(\alpha \times \beta) \\
  & \vdash S_1 \times (S_2 + S_3) \reduce S_1 \times S_2 + S_1 \times S_3
  \\
  \\
  & \vdash C(\alpha)^* \reduce C(\alpha^*) \\
  & \vdash \delta_{s, t}^* \reduce \delta_{s, t} \\
  & \vdash (S_1 + S_2)^* \reduce S_1^* + S_2^* \\
  & \vdash (S_1 \times S_2)^* \reduce S_1^* \times S_2^* \\
  & \vdash (S^*)^* \reduce S \\
  & \vdash (B \cdot K)^* \reduce K^\dagger \cdot B^\dagger
\end{align*}

\textbf{Remark: } We use the symbol $C$ to denoted the complex scalar in the module theory $\Sigma_\mathcal{S}$.



\subsubsection*{\textsf{SCR-DOT}}
\begin{align*}
  & \vdash \mathbf{0} \cdot K \reduce C(0) \\
  & \vdash B \cdot \mathbf{0} \reduce C(0) \\
  & \vdash (S.B) \cdot K \reduce S \times (B \cdot K) \\
  & \vdash B \cdot (S.K) \reduce S \times (B \cdot K) \\
  & \vdash (B_1 + B_2) \cdot K \reduce B_1 \cdot K + B_2 \cdot K \\
  & \vdash B \cdot (K_1 + K_2) \reduce B \cdot K_1 + B \cdot K_2 \\
  & \vdash \bra{s} \cdot \ket{t} \reduce \delta_{s, t} \\
\end{align*}

\begin{align*}
  & \vdash (B_1 \otimes B_2) \cdot \ket{t} \reduce (B_1 \cdot \ket{\fst\ t}) \times (B_2 \cdot \ket{\snd\ t}) \\
  & \vdash \bra{t} \cdot (K_1 \otimes K_2) \reduce (\bra{\fst\ t} \cdot K_1) \times (\bra{\snd\ t} \cdot K_2) \\
  & \vdash (B_1 \otimes B_2) \cdot (K_1 \otimes K_2) \reduce (B_1 \cdot K_1) \times (B_2 \cdot K_2)
\end{align*}

\textbf{Remark: } The difficulty here comes from Hilbert space structure. The intuition is that, we decompose the multiplication (inner product) when at least one side is explicitly in tensor product form.

\textbf{Remark:} Notice that we don't consider $\vdash (S.B) \cdot K \reduce (S^*).(B \cdot K)$. Inner product is linear (not conjugate linear) on $B$, because $B$ is already in the dual space.

\subsubsection*{\textsf{SCR-SORT}}
\begin{align*}
  & \vdash (B \cdot O) \cdot K \reduce B \cdot (O \cdot K) \\
  & \vdash \bra{s} \cdot ((O_1 \otimes O_2) \cdot K) \reduce ((\bra{\fst\ s} \cdot O_1) \otimes (\bra{\snd\ t} \cdot O_2)) \cdot K \\
  & \vdash (B_1 \otimes B_2) \cdot ((O_1 \otimes O_2) \cdot K) \reduce ((B_1 \cdot O_1) \otimes (B_2 \cdot O_2)) \cdot K \\
\end{align*}


\textbf{Remark: } The first rule sorts the multiplication to the right, which breaks the symmetry of ket and bra. The remaining three rules are for completion.

\subsubsection*{\textsf{ADJ-UNI}}
\begin{align*}
  & \vdash \textbf{0}^\dagger \reduce \textbf{0} \\
  & \vdash (X^\dagger)^\dagger \reduce X \\
  & \vdash (S.X)^\dagger \reduce S^*.(X^\dagger) \\
  & \vdash (X_1 + X_2)^\dagger \reduce X_1^\dagger + X_2^\dagger\\
\end{align*}

\subsubsection*{\textsf{ADJ-KET}}
\begin{align*}
  & \vdash \bra{t}^\dagger \reduce \ket{t}\\
  & \vdash (B \cdot O)^\dagger \reduce O^\dagger \cdot B^\dagger \\
  & \vdash (B_1 \otimes B_2)^\dagger \reduce B_1^\dagger \otimes B_2^\dagger
\end{align*}

\subsubsection*{\textsf{ADJ-BRA}}
\begin{align*}
  & \vdash \ket{t}^\dagger \reduce \bra{t}\\
  & \vdash (O \cdot K)^\dagger \reduce K^\dagger \cdot O^\dagger \\
  & \vdash (K_1 \otimes K_2)^\dagger \reduce K_1^\dagger \otimes K_2^\dagger
\end{align*}

\subsubsection*{\textsf{ADJ-OPT}}
\begin{align*}
  & \vdash \mathbf{1}_\mathcal{O}^\dagger \reduce \mathbf{1}_\mathcal{O}\\
  & \vdash (O_1 \cdot O_2)^\dagger \reduce O_1^\dagger \cdot O_2^\dagger \\
  & \vdash (O_1 \otimes O_2)^\dagger \reduce O_1^\dagger \otimes O_2^\dagger
\end{align*}

\subsubsection*{\textsf{SCR}}
\begin{align*}
  & \vdash C(0).X \reduce \mathbf{0}\\
  & \vdash C(1).X \reduce X \\
  & \vdash S.\mathbf{0} \reduce \mathbf{0} \\
  & \vdash S_1.(S_2.X) \reduce (S_1 \times S_2).X \\
  & \vdash S.(X_1 + X_2) \reduce S.X_1 + S.X_2
\end{align*}

\subsubsection*{\textsf{ADD}}
\begin{align*}
  & \vdash X + \mathbf{0} \reduce X \\
  & \vdash X + X \reduce C(1 + 1).X \\
  & \vdash S.X + X \reduce (S + C(1)).X \\
  & \vdash S_1.X + S_2.X \reduce (S_1 + S_2).X
\end{align*}

\subsubsection*{\textsf{KET-MLT}}
\begin{align*}
  & \vdash \textbf{0} \cdot K \reduce \textbf{0} \\
  & \vdash O \cdot \mathbf{0} \reduce \mathbf{0} \\
  & \vdash \textbf{1}_\mathcal{O} \cdot K \reduce K \\
  & \vdash (S.O) \cdot K \reduce S.(O \cdot K) \\
  & \vdash O \cdot (S.K) \reduce S.(O \cdot K) \\
  & \vdash (O_1 + O_2) \cdot K \reduce O_1 \cdot K + O_2 \cdot K \\
  & \vdash O \cdot (K_1 + K_2) \reduce O \cdot K_1 + O \cdot K_2 \\
  & \textcolor{red}{\vdash (K_1 \otimes B) \cdot K_2 \reduce (B \cdot K_2).K_1} \\
  & \textcolor{red}{\vdash (O_1 \cdot O_2) \cdot K \reduce O_1 \cdot (O_2 \cdot K)} \\
  & \textcolor{red}{\vdash (O_1 \otimes O_2) \cdot ((O_1' \otimes O_2') \cdot K) \reduce ((O_1 \cdot O_1') \otimes (O_2 \cdot O_2')) \cdot K} \\
  & \vdash (O_1 \otimes O_2) \cdot \ket{t} \reduce (O_1 \cdot \ket{\fst\ t}) \otimes (O_2 \cdot \ket{\snd\ t}) \\
  & \vdash (O_1 \otimes O_2) \cdot (K_1 \otimes K_2) \reduce (O_1 \cdot K_1) \otimes (O_2 \cdot K_2)
\end{align*}

\textbf{Remark: } Again, the difficulty comes from space structure. The intuition for reductions is also the same: decompose the multiplication when at least one side is explicitly in tensor product form.


\subsubsection*{\textsf{KET-TSR}}
\begin{align*}
  & \vdash \mathbf{0} \otimes K \reduce \mathbf{0} \\
  & \vdash K \otimes \mathbf{0} \reduce \mathbf{0} \\
  & \vdash \ket{s} \otimes \ket{t}\reduce\ket{(s, t)} \\
  & \vdash (S.K_1) \otimes K_2 \reduce S.(K_1 \otimes K_2) \\
  & \vdash K_1 \otimes (S.K_2) \reduce S.(K_1 \otimes K_2) \\
  & \vdash (K_1 + K_2) \otimes K_3 \reduce K_1 \otimes K_3 + K_2 \otimes K_3 \\
  & \vdash K_1 \otimes (K_2 + K_3) \reduce K_1 \otimes K_2 + K_1 \otimes K_3
\end{align*}

\textbf{Remark: } The rules for bra are symmetric to the rules for ket. Only the correspondence of rules in red are different:

\begin{align*}
  & \textcolor{red}{\vdash B_1 \cdot (K \otimes B_2) \reduce (B_1 \cdot K).B_2} \\
  & \textcolor{red}{\vdash B \cdot (O_1 \cdot O_2) \reduce (B \cdot O_1) \cdot O_2} \\
  & \textcolor{red}{\vdash (B \cdot (O_1 \otimes O_2)) \cdot (O_1' \otimes O_2') \reduce B \cdot ((O_1 \cdot O_1') \otimes (O_2 \cdot O_2'))}
\end{align*}

\subsubsection*{\textsf{OPT-OUTER}}
\begin{align*}
  & \vdash \mathbf{0} \otimes B \reduce \mathbf{0} \\
  & \vdash K \otimes \mathbf{0} \reduce \mathbf{0} \\
  & \vdash (S.K) \otimes B \reduce S.(K \otimes B) \\
  & \vdash K \otimes (S.B) \reduce S.(K \otimes B) \\
  & \vdash (K_1 + K_2) \otimes B \reduce K_1 \otimes B + K_2 \otimes B \\
  & \vdash K \otimes (B_1 + B_2) \reduce K \otimes B_1 + K \otimes B_2
\end{align*}

\subsubsection*{\textsf{OPT-MLT}}
\begin{align*}
  & \vdash \mathbf{0} \cdot O \reduce \mathbf{0} \\
  & \vdash O \cdot \mathbf{0} \reduce \mathbf{0} \\
  & \vdash \mathbf{1}_\mathcal{O} \cdot O \reduce O \\
  & \vdash O \cdot \mathbf{1}_\mathcal{O} \reduce O \\
  & \vdash (K \otimes B) \cdot O \reduce K \otimes (B \cdot O)\\
  & \vdash O \cdot (K \otimes B) \reduce (O \cdot K) \otimes B\\
  & \vdash (S.O_1) \cdot O_2 \reduce S.(O_1 \cdot O_2) \\
  & \vdash O_1 \cdot (S.O_2) \reduce S.(O_1 \cdot O_2) \\
  & \vdash (O_1 + O_2) \cdot O_3 \reduce O_1 \cdot O_3 + O_2 \cdot O_3 \\
  & \vdash O_1 \cdot (O_2 + O_3) \reduce O_1 \cdot O_2 + O_1 \cdot O_3 \\
  & \vdash (O_1 \cdot O_2) \cdot O_3 \reduce O_1 \cdot (O_2 \cdot O_3) \\
  & \vdash (O_1 \otimes O_2) \cdot (O_1' \otimes O_2') \reduce (O_1 \cdot O_1') \otimes (O_2 \cdot O_2') \\
  & \vdash (O_1 \otimes O_2) \cdot ((O_1' \otimes O_2') \cdot O_3) \reduce ((O_1 \cdot O_1') \otimes (O_2 \cdot O_2')) \cdot O_3
\end{align*}


\subsubsection*{\textsf{OPT-TSR}}
\begin{align*}
  & \vdash \mathbf{0} \otimes O \reduce \mathbf{0} \\
  & \vdash O \otimes \mathbf{0} \reduce \mathbf{0} \\
  & \vdash (K_1 \otimes B_1) \otimes (K_2 \otimes B_2) \reduce (K_1 \otimes K_2) \otimes (B_1 \otimes B_2) \\
  & \vdash (S.O_1) \otimes O_2 \reduce S.(O_1 \otimes O_2) \\
  & \vdash O_1 \otimes (S.O_2) \reduce S.(O_1 \otimes O_2) \\
  & \vdash (O_1 + O_2) \otimes O_3 \reduce O_1 \otimes O_3 + O_2 \otimes O_3 \\
  & \vdash O_1 \otimes (O_2 + O_3) \reduce O_1 \otimes O_2 + O_1 \otimes O_3
\end{align*}


\section{Confluence of DN}

We use \texttt{CiME2} to check the local confluence of the TRS of typed Dirac notation automatically. Because our TRS contains modulo theories and AC-symbols, we need to apply some the techniques:

\begin{itemize}
  \item consider a smallest instance of the complex scalar rewrite system and utilize the avatar lemma, and
  \item consider an extended system due to the AC-symbols.
\end{itemize}

The whole procedure is very similar to that of Lineal.

\subsection{Confluence modulo Theory and the Avatar Lemma}

First we introduce some concepts about modularity and the avatar lemma.

\begin{definition}[Subsumption]
  A terminating and confluent relation $S$ subsumes a relation $S_0$ if whenever $t \to_{S_0} u$, $t$ and $u$ have the same $S$-normal form.
\end{definition}

\begin{definition}[Commuting relations]
  Two relations $X$ and $Y$ are said to be commuting if whenever $t \to_X u$ and $t \to_Y v$, there exists a term $w$ such that $u \to_Y w$ and $v \to_X w$.
\end{definition}

\begin{proposition}[The avatar lemma] \cite{Arrighi2005} Let $X$, $S$ and $S_0$ be three relations defined on a set such that:
  \begin{itemize}
    \item $S$ is terminating and confluent;
    \item $S$ subsumes $S_0$;
    \item $S_0 \cup X$ is locally confluent;
    \item $X$ commutes with $S^*$.
  \end{itemize}
  Then, the relation $S \cup X$ is locally confluent.
\end{proposition}

We now present a smallest instantiation $\mathfrak{S}_0$ of a complext scalar rewrite system. 

\begin{definition}[The rewrite system $\mathfrak{S}_0$]
  The system $\mathfrak{S}_0$ is defined by the following rules:
  \begin{gather*}
    0 + \alpha \reduce \alpha\\
    0 \times \alpha \reduce 0\\
    1 \times \alpha \reduce \alpha\\
    \alpha \times (\beta + \gamma) \reduce \alpha \times \beta + \alpha \times \gamma\\
    0^* \reduce 0 \\
    1^* \reduce 1 \\
    (\alpha + \beta)^* \reduce \alpha^* + \beta^*\\
    (\alpha \times \beta)^* \reduce \alpha^* \times \beta^*\\
    (\alpha^*)^* \reduce \alpha
  \end{gather*}
  where $+$ and $\times$ are AC-symbols.
\end{definition}


\subsection{AC-rewriting and Extension Rules}
If a TRS $R$ contains AC-symbols, checking the critical pairs of $R$ is not enough to ensure the local confluence of $R$. This is because the LHS of rules can match the term unlocally. For example:
$$
(K_0 + K_1) + K_0 \reduce C(1 + 1).K_0 + K_1
$$
by the rule $\vdash K + K \reduce C(1 + 1).K$. We need to consider an extended system, as indicated by the following definition.

\begin{definition}[The extension rules]
  Let $X$ be a AC-rewrite system with AC symbols $f_1, \cdots, f_n$. We define the AC-rewrite system $X_{ext}$ as containing the same AC symbols as $X$, the same rules as $X$, plus the rule $f_i(t, x) \to f_i(u, x)$ for each rule $t \to u$ of $X$ where the head symbol of $t$ is $f_i$.
\end{definition}

\begin{proposition}
  The globally AC reduction relation of system $X$ is confluent if and only if the locally AC reduction relation of $X_{ext}$ is confluent.
\end{proposition}

And we can check the local confluence of locally AC reduction of $X_{ext}$ by calculating the critical pairs.

\begin{proposition}[$\mathfrak{S}_{0ext}$]
  The system $\mathfrak{S}_{0ext}$ is formed by the rules in $S_0$ and the rule
  \begin{align*}
    & (0 + \alpha) + \chi \reduce \alpha + \chi \\
    & (0 \times \alpha) \times \chi \reduce 0 \times \chi \\
    & (1 \times \alpha) \times \chi \reduce \alpha \times \chi \\
    & (\alpha \times (\beta + \gamma)) \times \chi \reduce (\alpha \times \beta + \alpha \times \gamma) \times \chi \\
  \end{align*}
\end{proposition}

\begin{proposition}
  The system $\mathfrak{DN}_{ext}$ is formed by the rules in $\mathfrak{DN}$ and the rule
  \begin{align*}
    & (C(0) + a) + x \reduce a + x \\
    & (C(a) + C(b)) + x \reduce C(a + b) + x \\
    & (S + S) + x \reduce (C(1 + 1) \times S) + x \\
    & ((C(a) \times S) + S) + x \reduce (C(a + 1) \times S) + x \\
    & ((C(a) \times S) + (C(b) \times S)) + x \reduce (C(a + b) \times S) + x \\
    \\
    & (C(0) \times a) \times x \reduce C(0) \times x \\
    & (C(1) \times a) \times x \reduce a \times x \\
    & (C(a) \times C(b)) \times x \reduce C(a \times b) \times x \\
    & (S_1 \times (S_2 + S_3)) \times x \reduce ((S_1 \times S_2) + (S_1 \times S_3)) \times x \\
    \\
    & (K + \mathbf{0}_\mathcal{K}) + x \reduce K + x \\
    & (K + K) + x \reduce C(1 + 1).K + x \\
    & (S.K + K) + x \reduce (S + 1).K + x \\
    & (S_1.K + S_2.K) + x \reduce (S_1 + S_2).K + x \\
    \\
    & \textrm{(same for bra)}\\
    \\
    & (O + \mathbf{0}_\mathcal{O}) + x \reduce O + x \\
    & (O + O) + x \reduce C(1 + 1).O + x \\
    & (S.O + O) + x \reduce (S + 1).O + x \\
    & (S_1.O + S_2.O) + x \reduce (S_1 + S_2).O + x
  \end{align*}
\end{proposition}

\begin{proposition}
  The system $\mathfrak{S}_{0ext} \cup \mathfrak{DN}_{ext}$ is locally confluent.
\end{proposition}
\begin{proof}
  Checked by \texttt{CiME2}.
\end{proof}

\subsection{Checking by \texttt{CiME}}

We encoded the typed Dirac notation in a simple TRS and checked the confluence of the whole system. Here is a summary of the rules.


\begin{center}
  \begin{tabular}{c|c}
  \hline
  Type & Rule Number \\
  \hline
  type checking & 27 \\
  overloading polymorphic symbols & 22 \\
  complex scalar avatar & 9 \\
  Dirac notation & 141 \\
  AC-symbol extension rules & 25 \\
  \hline
  Total & 224 \\
  \hline
  \end{tabular}
\end{center}

And all the 3133 critical pairs are joinable.

\subsubsection*{About Reduandancy}
I also checked through a \texttt{Python} script that removing any of the reduction rule will lead to non-confluence or change of the equational theory. For example, I found that removing 
$$
\vdash (\fst\ e, \snd\ e)\reduce e
$$
or
$$
\vdash (K_1 \otimes B_1) \otimes (K_2 \otimes B_2) \reduce (K_1 \otimes K_2) \otimes (B_1 \otimes B_2)
$$
respectively will still lead to a confluence TRS, but the equivalence induced by the TRS will be be changed.


\section{Termination of DN}

Termination tool: see \url{https://link.springer.com/chapter/10.1007/978-3-030-17502-3_10}

May be we can try \texttt{MU-TERM}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Extension: Delta*}

In the backbone rewriting system DN, we don't attempt to reduce Delta operators $\delta_{s, t}$ to constants $0$ or $1$. This is because the complete reduction needs some semantic analysis and can be quite difficult. This section tries to find such a good extension.


To demonstrate the difficulty, we first consider the following example:
$$
\delta_{i, j} \times \delta_{i, k} = \delta_{i, j} \times \delta_{j, k}.
$$
This equality holds, but it is hard to detect merely by the syntax. In general, The equality and reduction of Delta operators need the semantic analysis, which is presented below.


\subsubsection*{\textsf{DELTA-COMPLETE}}

\begin{align*}
  & \textsc{(DeltaEQ)} && \frac{(\bigwedge_i s_i =_\textsf{BASIS} t_i) \leftrightarrow (\bigwedge_i s_i' =_\textsf{BASIS} t_i') \textrm{ is valid}}{\prod_i \delta_{s_i, t_i} = \prod_i \delta_{s_i', t_i'}} \\
  \\
  & \textsc{(Delta1)} && 
  \frac{\bigwedge_i s_i =_\textsf{BASIS} t_i \textrm{ is valid}}{ \prod_i \delta_{s_i, t_i} \reduce 1}
  \\
  \\
  & \textsc{(Delta0)} && 
  \frac{\bigwedge_i s_i =_\textsf{BASIS} t_i \textrm{ is not satisfiable}}{ \prod_i \delta_{s_i, t_i} \reduce 0}
\end{align*}


\yx{We need to prove that the backbone system together with these rules are confluent.}

\subsection{Extension for Delta Operator (simple version)}
It's impractical to fully deicide the three conditions, espacially when the atomic basis $\mathfrak{B}$ is complicated. Therefore we present here a simpler extension to rewrite these Delta operators in common cases.

\subsubsection*{\textsf{DELTA*}}
\begin{align*}
  & \textsc{(Delta1)} && 
  \vdash \delta_{s, s} \reduce 1
  \\
  \\
  & \textsc{(Delta0)} &&
  \frac{s, t \text{ are different closed terms}}{\vdash \delta_{s, t} \reduce 0}
\end{align*}

\subsection{Extension for Delta Operator (SMT solver)}
We can use a SMT solver to check the conditions for the equality \textbf{DeltaEQ} and rules in \textsf{DELTA-COMPLETE}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Extension: Sum and Transpose}

\begin{definition}[DNE]
    The \textbf{language of Dirac Notation Extended}, denoted as $\mathfrak{DNE}(\Sigma_\mathcal{B}, \Sigma_\mathcal{S})$, consists of the same sorts as $\mathfrak{DN}(\Sigma_\mathcal{B}, \Sigma_\mathcal{S})$ with the following new symbols:
    \begin{align*}
        & S ::= \sum_i S \\
        & K ::= B^\top\ |\ \sum_i K \\
        & B ::= K^\top\ |\ \sum_i B \\
        & O ::= O^\top\ |\ \sum_i O
    \end{align*}
    The index $i$ for summation is a bind variable. The common considerations for bind variables are applied here: $\alpha$-conversion and substitutions.
\end{definition}


\section{TRS for DNE}

\begin{definition}[TRS $\mathfrak{DNE}$]
    The AC-rewrite system $\mathfrak{DNE}$ consists of all the rules in $\mathfrak{DN}$ as well as the rules in this section.
\end{definition}

\subsubsection*{\textsf{KET-TRANS}}
\begin{align*}
  & \mathbf{0}_\mathcal{B}^\top \reduce \mathbf{0}_\mathcal{K} \\
  & \bra{s}^\top \reduce \ket{s} \\
  & (K^\dagger)^\top \reduce (K^\top)^\dagger \\
  & (K^\top)^\top \reduce K \\
  & (S . B)^\top \reduce S . B^\top \\
  & (B_1 + B_2)^\top \reduce B_1^\top + B_2^\top \\
  & (B \cdot O)^\top \reduce O^\top \cdot B^\top \\
  & (B_1 \otimes B_2)^\top \reduce B_1^\top \otimes B_2^\top
\end{align*}


\subsubsection*{\textsf{BRA-TRANS}}
\begin{align*}
  & \mathbf{0}_\mathcal{K}^\top \reduce \mathbf{0}_\mathcal{B} \\
  & \ket{s}^\top \reduce \bra{s} \\
  & (B^\dagger)^\top \reduce (B^\top)^\dagger \\
  & (B^\top)^\top \reduce B \\
  & (S . K)^\top \reduce S . K^\top \\
  & (K_1 + K_2)^\top \reduce K_1^\top + K_2^\top \\
  & (O \cdot K)^\top \reduce K^\top \cdot O^\top \\
  & (K_1 \otimes K_2)^\top \reduce K_1^\top \otimes K_2^\top
\end{align*}


\subsubsection*{\textsf{OPT-TRANS}}
\begin{align*}
  & \mathbf{0}_\mathcal{O}^\top \reduce \mathbf{0}_\mathcal{O} \\
  & \mathbf{1}_\mathcal{O}^\top \reduce \mathbf{1}_\mathcal{O} \\
  & (K \otimes B)^\top \reduce B^\top \otimes K^\top \\
  & (O^\dagger)^\top \reduce (O^\top)^\dagger \\
  & (O^\top)^\top \reduce O \\
  & (S . O)^\top \reduce S . O^\top \\
  & (O_1 + O_2)^\top \reduce O_1^\top + O_2^\top \\
  & (O_1 \cdot O_2)^\top \reduce O_2^\top \cdot O_1^\top \\
  & (O_1 \otimes O_2)^\top \reduce O_1^\top \otimes O_2^\top
\end{align*}

\textbf{Remark:} It has been checked by CiME2 that for the TRS $\mathfrak{DN}$ extended with transpose rules, the only unjoinable critical pairs are joinable with the equational theory $B\cdot K = K^\top \cdot B^\top$.


\subsubsection*{\textsf{SUM-ELIM}}

\begin{align*}
  & \sum_i C(0) \reduce C(0) \\
  & \sum_i \mathbf{0} \reduce \mathbf{0}
\end{align*}

One common condition is attached to all the following rules: variable $i$ does not have free appearance in term $s$

Here $S.A$ is interpreted as three cases: $S.K$, $S.B$ and $S.O$.
\begin{align*}
  & \sum_i \delta_{i, s} \reduce C(1) \\
  & \sum_i (\delta_{i, s} \times S) \reduce S[i:=s] \\
  & \sum_i (\delta_{i, s}.A) \reduce A[i:=s] \\
  & \sum_i ((\delta_{i, s} \times S).A) \reduce S[i:=s].A[i:=s] \\
\end{align*}


\yx{Terms like $\sum_i \delta_{i,j}$ are not simplified.}

\yx{In principle we will want to count the ``times'' the the two indices be equivalent to each other. For example,
$$
\sum_i \delta_{i, i^2} \reduce 2
$$
But in general this is not possible. But we can limit the case to ``i is the bind variable and i is not a free variable in expression j''.
}

The following rules are for ket, bra and operators respectively.
\begin{align*}
  & \sum_i (\bra{i} \cdot K).\ket{i} \reduce K \\
  & \sum_i (B \cdot \ket{i}).\bra{i} \reduce B \\
  & \sum_i \sum_j (\bra{i} A \ket{j}).\ket{i}\bra{j} \reduce A \\
  & \sum_i \sum_j (\bra{i} A \ket{j}).\ket{j}\bra{i} \reduce A^\top
\end{align*}

\yx{One may expect these rules to be applied in broader cases, for example:
$$
\sum_i \sum_j (\bra{i} A \ket{j} . \ket{j}\bra{i} \cdot B) \reduce A \cdot B,
$$
but this is not hold in general: $B$ can be dependent on $i$.
}

\subsubsection*{\textsf{SUM-DIST}}
Here the zero operator $\mathbf{0}$ is interpreted in three sorts: ket, bra and operator. The same for $A^\dagger$, $A^\top$, $S.A$ and addition.

Here $A \cdot B$ is interpreted as four cases: $B \cdot K$, $O \cdot K$, $B \cdot O$ and $O_1 \cdot O_2$. $A \otimes B$ is interpreted as four cases: $K_1 \otimes K_2$, $B_1 \otimes B_2$, $K \otimes B$ and $O_1 \otimes O_2$.

\begin{align*}
  & (\sum_i S_1) \times S_2 \reduce \sum_i (S_1 \times S_2) \\
  & (\sum_i S)^* \reduce \sum_i S^* \\
  & (\sum_i A)^\dagger \reduce \sum_i A^\dagger \\
  & (\sum_i A)^\top \reduce \sum_i A^\top \\
  & S.(\sum_i A) \reduce \sum_i (S.A) \\
  & (\sum_i S). A \reduce \sum_i (S.A) \\
  & (\sum_i A) \cdot B \reduce \sum_i (A \cdot B) \\
  & A \cdot (\sum_i B) \reduce \sum_i (A \cdot B) \\
  & (\sum_i A) \otimes B \reduce \sum_i (A \otimes B) \\
  & A \otimes (\sum_i B) \reduce \sum_i (A \otimes B)
\end{align*}

\yx{problem: when pushing inside, the information of bind variable independence is lost. So we should do in the opposite way.}

\yx{Maybe we want to do in the opposite way: pull everything out as much as possible. But those rules involve checking whether the subterm to be pulled out is dependent on the bind variable. But this strategy makes matching elimination rule simpler.}

\subsubsection*{\textsf{SUM-ADD}}
Here the addition $A + B$ is interpreted in four sorts: scalar, ket, bra and operator.
\begin{align*}
  & (\sum_i A) + (\sum_j B) \reduce \sum_k (A[i:=k] + B[j:=k])
\end{align*}

\section{Problems \& Techniques for $\mathfrak{DNE}$}

\subsection{Equivalence checking in Wolfram Engine}

\subsubsection*{Problem}

The module for complex scalars and atomic basis are assumed to be completed. That is, semantical equivalence is identical to having the same syntax. But this is not always true in Wolfram language: terms having different normal forms can be mathematically equivalent. Here is an example:

$ e^{i(a+b)} $ and $ e^{ia + ib} $ are equivalent in maths but they have different normal forms in Wolfram language. Nevertheless, this can still be checked by computing $\text{FullSimplify}[e^{i(a+b)} == e^{ia + ib}]$ and this will be reduced to True.

\subsubsection*{Solution}

We adopt a unique table for Wolfram expressions and search in the table whenever we create a new one. This ensures that semantically equivalent terms only have once instance in the system. While this implementation is inefficient during rewriting, we only transform the normal forms using unique scalar tables when comparing equivalence.

\subsection{\textsf{DOT-DUAL} equational theory}

\subsubsection*{Problem}
The TRS $\mathfrak{DNE}$ is not complete for \textsf{DOT-DUAL} equational theory.

The \textsf{DOT-DUAL} equational theory is expressed as:
$$
B \cdot K = K^\top \cdot B^\top.
$$
We encountered difficulty in finding the canonical form. Our solution is to define an internal commutative symbol $\textrm{JUX}$ to juxtapose the two possible expressions, with the following rule:
$$
\textrm{(DOT-DUAL-JUX)} \qquad B \cdot K \reduce \textrm{JUX}(B \cdot K, K^\top \cdot B^\top).
$$
$B\cdot K$ and $K^\top \cdot B^\top$ will be joinable with this rule. But there are two problems: it is not terminating, and its hard to prove confluence. The second problem comes from the fact that normally the two subterms $A, B$ in $\textrm{JUX}(A, B)$ are semnatically equivalent, but the standard framework of term rewriting does not support such constraint. 

\subsubsection*{Solution}
We introduce a new framework called ``term rewriting with multiple sections'' to separate the terms for rewriting calculation and equivalence comparison. There are two main points:
\begin{enumerate}
    \item Rewrite terms using $\mathfrak{DNE}$.
    \item When comparing equivalence extended with \textsf{DOT-DUAL}, we transform the normal term of $\mathfrak{DNE}$ using $\textrm{juxt}$, which apply the rule DOT-DUAL-JUX iteratively once, and then rewrite the term again using $\mathfrak{DNE}$.
\end{enumerate}

\begin{center}
    \includegraphics*[width=.8\textwidth]{fig/DNE-JUX.png}
\end{center}

\subsection{\textsf{SUM-SWAP} equational theory}
\subsubsection*{Problem}
The TRS $\mathfrak{DNE}$ is not complete for \textsf{SUM-SWAP} equational theory, which is:
$$
\sum_i \sum_j A = \sum_j \sum_i A.
$$
This equational theory can be understood as the result from AC property of addition. Again, we cannot find the canonical form to join the terms on the two sides.

\subsubsection*{Solution}
Similar to the techniques of DOT-DUAL-JUX, we introduce another internal AC symbol $\textrm{SUMEQ}$, with the following rule:

$$
\textrm{(SUM-SWAP-JUX)} \qquad \sum_i \sum_j A \reduce (\sum_i \sum_j A)\ \textrm{SUMEQ}\ (\sum_j \sum_i A)
$$
Then we introduce another rewriting section, which first apply the rule SUM-SWAP-JUX once, and then rewrite again using $\mathfrak{DNE}$. The syntactic equivalence after this transformation should be equivalent to the equivalence of $\mathfrak{DNE}$ normal terms with \textsf{SUM-SWAP} equational theory.


\subsection{Unjoinable Critical Pair}
\subsubsection*{Problem}
Unjoinable pair:
$$
\sum_i ((\delta_{\fst(i), s} \times \delta_{\snd(i), t}).\ket{i})\reducefrom \sum_i (\delta_{i, (s, t)} . \ket{i}) \reduce \ket{(s, t)}
$$

\subsubsection*{Solution}
Always put \textsf{SUM} rules in front of others?

Although it does not fix the confluence problem, it's still useful in practice, because soundness still holds. As long as terms are equivalent under some rewriting strategy then they are equivalent in semantics.




\section{Typed Dirac Notation}

Now we build a type system based on the untyped Dirac notation. With the typing information, we are able to achieve the polymorphism of the universal application symbol, which is close to how Dirac notation is dealt with in practice.

\subsubsection*{Polymorphism of Universal Application}

I believe the essence of Dirac notation is the polymorphism of universal application, which means that the same symbol is overloaded as different funtions based on the type of operands. We often use a universal application binary symbol (denoted as $\circ$) to concatenate subterms. For example, 
$$
\bra{a} \circ \ket{b} \circ \bra{c} \circ \ket{d} = \< a | b \> \< c | d \>.
$$
This term has no ambiguity because universal application is expected to be associative. And $\circ$ is overloaded differently based on how we associate the calculation. For example,
$$
(\bra{a} \circ \ket{b}) \circ (\bra{c} \circ \ket{d}) = \< a | b \> \times \< c | d \>
$$
$$
\bra{a} \circ (\ket{b} \circ \bra{c}) \circ \ket{d} = \< a | \cdot | b \>\< c | \cdot | d \>
$$

The complete list of overloading is given by the table:

\begin{center}
  \begin{tabular}{|c|c|c|c|c|}
    \hline
    $X \circ Y$ & $Y \in \mathcal{S}$ & $Y\in \mathcal{K}$ & $Y \in \mathcal{B}$ & $Y \in \mathcal{O}$ \\
    \hline
    $X \in \mathcal{S}$ & $S_X \times S_Y$ & $S_X.K_Y$ & $S_X.B_Y$ & $S_X.O_Y$ \\
    \hline
    $X \in \mathcal{K}$ & $S_Y.K_X$ & $K_X \otimes K_Y$ & $ K_X \otimes B_Y$ &  \\
    \hline
    $X \in \mathcal{B}$ & $S_Y.B_X$ & $B_X \cdot K_Y$ & $B_X \otimes B_Y$ & $B_X \cdot O_Y$ \\
    \hline
    $X \in \mathcal{O}$ & $S_Y.O_X$ & $O_X \cdot K_Y$ &  & $O_X \cdot O_Y$ \\
    \hline
  \end{tabular}
\end{center}


A major topic of this work is to \textbf{prove the associativity of the universal application symbol} constructed in the TRS.

\subsubsection*{Polymorphism of otimes and cdot}
Similar to the universal application symbol $\circ$, we also use $A \otimes B$ and $A \cdot B$ in a polymorphic way. This is also encoded in the \texttt{CiME} script.



\subsubsection*{Type Definition}

\begin{definition}[Types]
  The type for basis is defined by
  \begin{align*}
    \tau ::= T\ |\ (\tau * \tau),
  \end{align*}
  Here $T$ is the type for atomic bases.
  The type for scalar, ket, bra and operator are defined by $\mathcal{S}$, $\mathcal{K}(\tau)$, $\mathcal{B}(\tau)$ and $\mathcal{O}(\tau, \sigma)$, respectively.
\end{definition}

\subsection{typing rules}
  A typing assumption has the form $x : \tau$, meaning variable $x$ has the type $\tau$. A typing context $\Gamma$ consists of typing assumptions and each variable appears only once.

  A typing judgement $\vdash e : \sigma$ indicates that $e$ is a term of type $\sigma$ in context $\Gamma$. The well-typed terms are defined by the following rules.

\subsubsection*{Typing of Basis}
  \begin{gather*}
    \frac{x : \sigma \in \Gamma}{\vdash x : \sigma}
    \qquad 
    \vdash b : T\\
    \\
    \frac{\vdash t_1 : \tau \qquad \vdash t_2 : \sigma}{\vdash (t_1, t_2) : ( \tau * \sigma )} \\
    \\
    \frac{\vdash t : ( \tau * \sigma )}{\vdash \fst\ t : \tau}
    \qquad
    \frac{\vdash t : ( \tau * \sigma )}{\vdash \snd\ t : \sigma}
  \end{gather*}

\subsubsection*{Typing of Scalar}
  \begin{gather*}
    \frac{x : \mathcal{S} \in \Gamma}{\vdash x : \mathcal{S}}
    \qquad 
    \vdash C(\alpha) : \mathcal{S}
    \qquad
    \frac{\vdash s : \tau \qquad \vdash t : \tau}{\vdash \delta_{s, t} : \mathcal{S}} \\
    \\
    \frac{\vdash S_1 : \mathcal{S} \qquad \vdash S_2 : \mathcal{S}}{\vdash S_1 + S_2 : \mathcal{S}}
    \qquad
    \frac{\vdash S_1 : \mathcal{S} \qquad \vdash S_2 : \mathcal{S}}{\vdash S_1 \times S_2 : \mathcal{S}} \\
    \\
    \frac{\vdash S : \mathcal{S}}{\vdash S^* : \mathcal{S}} \\
    \\
    \frac{\vdash B : \mathcal{B}(\tau) \qquad \vdash K : \mathcal{K}(\tau)}{\vdash B \cdot K : \mathcal{S}}
  \end{gather*}


\subsubsection*{Typing of Ket}
  \begin{gather*}
    \frac{x : \mathcal{K}(\tau) \in \Gamma}{\vdash x : \mathcal{K}(\tau)}
    \qquad
    \vdash \zeroK{\tau} : \mathcal{K}(\tau)
    \qquad
    \frac{\vdash t : \tau}{\vdash \ket{t} : \mathcal{K}(\tau)} \\
    \\
    \frac{\vdash B : \mathcal{B}(\tau)}{\vdash B^\dagger : \mathcal{K}(\tau)}
    \qquad
    \frac{\vdash S : \mathcal{S} \qquad \vdash K : \mathcal{K}(\tau)}{\vdash S.K : \mathcal{K}(\tau)} \\
    \\
    \frac{\vdash K_1 : \mathcal{K}(\tau) \qquad \vdash K_2 : \mathcal{K}(\tau)}{\vdash K_1 + K_2 : \mathcal{K}(\tau)} \\
    \\
    \frac{\vdash O : \mathcal{O}(\tau, \sigma) \qquad \vdash K : \mathcal{K}(\sigma)}{\vdash O \cdot K : \mathcal{K}(\tau)} \\
    \\
    \frac{\vdash K_1 : \mathcal{K}(\tau_1) \qquad \vdash K_2 : \mathcal{K}(\tau_2)}{\vdash K_1 \otimes K_2 : \mathcal{K}(\tau_1 * \tau_2)}
  \end{gather*}


\subsubsection*{Typing of Bra}
  \begin{gather*}
    \frac{x : \mathcal{B}(\tau) \in \Gamma}{\vdash x : \mathcal{B}(\tau)}
    \qquad
    \vdash \zeroB{\tau} : \mathcal{B}(\tau)
    \qquad
    \frac{\vdash t : \tau}{\vdash \bra{t} : \mathcal{B}(\tau)} \\
    \\
    \frac{\vdash K : \mathcal{K}(\tau)}{\vdash K^\dagger : \mathcal{B}(\tau)}
    \qquad
    \frac{\vdash S : \mathcal{S} \qquad \vdash B : \mathcal{B}(\tau)}{\vdash S.B : \mathcal{B}(\tau)} \\
    \\
    \frac{\vdash B_1 : \mathcal{B}(\tau) \qquad \vdash B_2 : \mathcal{B}(\tau)}{\vdash B_1 + B_2 : \mathcal{B}(\tau)} \\
    \\
    \frac{\vdash B : \mathcal{B}(\tau) \qquad \vdash O : \mathcal{O}(\tau, \sigma)}{\vdash B \cdot O : \mathcal{B}(\sigma)} \\
    \\
    \frac{\vdash B_1 : \mathcal{B}(\tau_1) \qquad \vdash B_2 : \mathcal{B}(\tau_2)}{\vdash B_1 \otimes B_2 : \mathcal{B}(\tau_1 * \tau_2)}
  \end{gather*}


\subsubsection*{Typing of Operator}
  \begin{gather*}
  \frac{x : \mathcal{O}(\tau, \sigma) \in \Gamma}{\vdash x : \mathcal{O}(\tau, \sigma)}
  \qquad
  \vdash \zeroO{\tau, \sigma} : \mathcal{O}(\tau, \sigma) 
  \qquad
  \vdash \textbf{1}_{\mathcal{O}(\tau)} : \mathcal{O}(\tau, \tau) 
  \qquad
  \frac{\vdash K : \mathcal{K}(\tau) \qquad \vdash B : \mathcal{B}(\sigma)}{\vdash K \otimes B : \mathcal{O}(\tau, \sigma)} \\
  \\
  \frac{\vdash O : \mathcal{O}(\tau, \sigma)}{\vdash O^\dagger : \mathcal{O}(\sigma, \tau)}
  \qquad
  \frac{\vdash S : \mathcal{S} \qquad \vdash O : \mathcal{O}(\tau, \sigma)}{\vdash S.O : \mathcal{O}(\tau, \sigma)} \\
  \\
  \frac{\vdash O_1 : \mathcal{O}(\tau, \sigma) \qquad \vdash O_2 : \mathcal{O}(\tau, \sigma)}{\vdash O_1 + O_2 : \mathcal{O}(\tau, \sigma)} \\
  \\
  \frac{\vdash O_1 : \mathcal{O}(\tau, \sigma) \qquad \vdash O_2 : \mathcal{O}(\sigma, \rho)}{\vdash O_1 \cdot O_2 : \mathcal{O}(\tau, \rho)} \\
  \\
  \frac{\vdash O_1 : \mathcal{O}(\tau_1, \sigma_1) \qquad \vdash O_2 : \mathcal{O}(\tau_2, \sigma_2)}{\vdash O_1 \cdot O_2 : \mathcal{O}(\tau_1 * \tau_2, \rho_1 * \rho_2)}
\end{gather*}

\textbf{Remark: } The type system is transformed and encoded in the simplest TRS. All the typing rules are treated as reduction rules.