\chapter{20240209}

\newcommand*{\unit}{\texttt{unit}}
\newcommand*{\utt}{\texttt{tt}}
\newcommand*{\fst}{\texttt{fst}}
\newcommand*{\snd}{\texttt{snd}}
\newcommand*{\reduce}{\ \triangleright\ }
\newcommand*{\reducefrom}{\ \triangleleft\ }

\newcommand*{\zeroK}[1]{\mathbf{0}_{\mathcal{K}(#1)}}
\newcommand*{\zeroB}[1]{\mathbf{0}_{\mathcal{B}(#1)}}
\newcommand*{\zeroO}[1]{\mathbf{0}_{\mathcal{O}(#1)}}


\section{Problem: axiom of inner product}
We have an axiom in the Dirac notation algebra: $B \cdot K = (K^\top)^* \cdot (B^\top)^*$. To make our TRS complete, the two sides of the equation should have the same canonical form, but I have problem achieving this.

The problem comes from $(x^\top)^\top = (x^*)^* = x$. Consider the critical pair: $((K_1^\top)^* \cdot K_2, (K_2^\top)^* \cdot K_1)$: they should be equivalent according to the axiom, but the only differrence between the two expression is the variable name, therefore neither of them can is the suitable canonical form.

\yx{Now I believe there is no syntactic solution to this problem. We have to make use of E-TRS.}


\section{The langauge of Dirac Notation}

\begin{definition} [atomic basis signature]
  The \textbf{atomic basis signature} $\Sigma_\mathcal{B}$ is an arbitrary signature.
\end{definition}

\begin{definition} [complex scalar signature]
  The \textbf{complex scalar signature} $\Sigma_\mathcal{S}$ contains constant symbols $0, 1, \text{Â½}$, a unary symbol $*$ and binary symbols $+, \times$.
\end{definition}

\begin{definition}[language of Dirac Notation]
  The \textbf{language of Dirac Notation}, denoted as $\mathcal{DN}(\Sigma_\mathcal{B}, \Sigma_\mathcal{S})$, has five sorts defined as follows:
  \begin{align*}
    & \mathcal{A} \textrm{(base)} && t ::= x\ |\ b\ |\ (t, t)\ |\ \fst\ t\ |\ \snd\ t \\
    & \mathcal{S} \textrm{(scalar)} && S ::= x\ |\ C(\alpha)\ |\ \delta_{t, t}\ |\ S + S\ |\ S \times S\ |\ S^*\ |\ B \cdot K\ |\ B \odot K \\
    & \mathcal{K} \textrm{(ket)} && K ::= x\ |\ \mathbf{0}_\mathcal{K}\ |\ \ket{t}\ |\ B^\dagger\ |\ S.K\ |\ K + K\ |\ O \cdot K\ |\ K \otimes K \\
    & \mathcal{B} \textrm{(bra)} && B ::= x\ |\ \mathbf{0}_\mathcal{B}\ |\ \bra{t}\ |\ K^\dagger\ |\ S.B\ |\ B + B\ |\ B \cdot O\ |\ B \otimes B \\
    & \mathcal{O} \textrm{(operator)} && O ::= x\ |\ \mathbf{0}_\mathcal{O}\ |\ \mathbf{1}_\mathcal{O}\ |\ K \otimes B\ |\ O^\dagger\ |\ S.O\ |\ O + O\ |\ O \cdot O\ |\ O \otimes O
  \end{align*}
  Here $x$ is a variable, $b$ is a closed term of $\Sigma_\mathcal{B}$ and $\alpha$ is a closed term of $\Sigma_\mathcal{S}$.

\end{definition}

\textbf{Remark: } Although we use the same symbol in different sorts ($B \cdot K$ and $O \cdot K$, for example), they are actually different funtions and can be easily distinguished by the context. This is also reflected in the \texttt{CiME} script.


\yx{I encountered some confluence problem for conjugate and transpose, and the natural solution is to consider them as a whole ($\dagger$), which is also more common in quantum computing.}


\section{Dirac Notation Algebra}

With the language $\mathcal{DN}(\Sigma_\mathcal{B}, \Sigma_\mathcal{S})$, we want to define when two terms are equal. This is described by an algebra with axioms.

\yx{I didn't notice such a formal definition of Dirac notation algebra anywhere, so I came up with one from the TRS below.}

\yx{This should imply the axioms of the vector space in Lineal.}

\begin{align*}
  \fst\ (s, t) = s \\
  \snd\ (s, t) = t \\
  (\fst\ s, \snd\ s) = s \\
  \\
  C(\alpha) + C(\beta) = C(\alpha + \beta) \\
  C(\alpha) \times C(\beta) = C(\alpha \times \beta) \\
  C(\alpha)^* = C(\alpha^*) \\
  C(0) + a = a \\
  C(0) \times a = C(0) \\
  C(1) \times a = a \\
  a \times (b + c) = a \times b + a \times c \\
  \delta_{s, t}^* = \delta_{s, t} \\
  (a + b)^* = a^* + b^* \\
  (a \times b)^* = a^* \times b^* \\
  (a^*)^* = a \\
  (B \cdot K)^* = K^\dagger \cdot B^\dagger \\
  \vdots \\
  B \cdot (O \cdot K) = (B \cdot O) \cdot K \\
  (O_1 \otimes O_2) \cdot (K_1 \otimes K_2) = (O_1 \cdot K_1) \otimes (O_2 \cdot K_2)
\end{align*}

\yx{Do we really need such an algebra? It seems that the algebra will not be much simpler than the TRS.}


\section{Semantics}
Constructed in CoqQ.

\section{Module Theories}

We want to study the theory of Dirac notations modulo the scalars and classical basis. This idea is inspired by the Lineal paper \cite{Arrighi2017}.

\begin{definition}[complex scalar rewrite system]
  A \textbf{complex scalar rewrite system} is a rewrite system $\mathfrak{S}$ for $\Sigma_\mathcal{S}$ such that:
  \begin{itemize}
    \item $\mathfrak{S}$ is terminating and ground confluent,
    \item $+$ and $\times$ are AC-symbols,
    \item for all closed terms $\alpha$, $\beta$ and $\gamma$, the pair of terms
      \begin{itemize}
        \item $0 + \alpha$ and $\alpha$
        \item $0 \times \alpha$ and $0$,
        \item $1 \times \alpha$ and $\alpha$,
        \item $\alpha \times (\beta + \gamma)$ and $\alpha \times \beta + \alpha \times \gamma$,
        \item $(\alpha + \beta)^*$ and $\alpha^* + \beta^*$,
        \item $(\alpha \times \beta)^*$ and $\alpha^* \times \beta^*$,
        \item $(\alpha^*)^*$ and $\alpha$,
      \end{itemize}
      have the same normal forms,
    \item $0$ and $1$ are normal terms.
  \end{itemize}
\end{definition}


\begin{definition}[atomic basis rewrite system]
  An \textbf{atomic basis rewrite system} $\mathfrak{B}$ is a terminating and ground confluent rewrite system for $\Sigma_\mathcal{B}$.
\end{definition}


\section{Untyped Dirac Notation}

\begin{definition}[internal language]
  
\end{definition}


We first present the untyped Dirac Notation rewrite system. This is the internal langauge with no ambiguity.


\begin{definition} [TRS $\mathfrak{D}$]
  The AC-rewrite system $\mathfrak{D}$ conssits of all the rules in Sec.\ref{sec: typed_dirac_rules}.
  The AC-symbols are $+$ (for all sorts) and $\times$. The commutative symbol is $\delta_{s, t}$.
\end{definition}

\subsection{Reduction Rules}
\label{sec: typed_dirac_rules}
\subsubsection*{\textsf{BASIS}}
\begin{align*}
    \vdash \fst\ (e_1, e_2) \reduce e_1
    \qquad
    \vdash \snd\ (e_1, e_2) \reduce e_2
    \qquad
    \vdash (\fst\ e, \snd\ e)\reduce e
\end{align*}

\subsubsection*{\textsf{DELTA}}
\begin{align*}
  & \vdash \delta_{u, (s, t)} \reduce \delta_{\fst\ u, s} \times \delta_{\snd\ u, t} \\
  & \vdash \delta_{\fst\ u, \fst\ v}\times\delta_{\snd\ u, \snd\ v} \reduce \delta_{u, v}
\end{align*}

\textbf{Remark: } These rules are for completion.


\subsubsection*{\textsf{SCR-COMPLEX}}
\begin{align*}
  & \vdash C(0) + S \reduce S \\
  & \vdash C(\alpha) + C(\beta) \reduce C(\alpha + \beta) \\
  & \vdash S + S \reduce C(1 + 1) \times S \\
  & \vdash C(\alpha) \times S + S \reduce C(\alpha + 1) \times S \\
  & \vdash C(\alpha) \times S + C(\beta) \times S \reduce C(\alpha + \beta) \times S
  \\
  \\
  & \vdash C(0) \times S \reduce C(0) \\
  & \vdash C(1) \times S \reduce S \\
  & \vdash C(\alpha) \times C(\beta) \reduce C(\alpha \times \beta) \\
  & \vdash S_1 \times (S_2 + S_3) \reduce S_1 \times S_2 + S_1 \times S_3
  \\
  \\
  & \vdash C(\alpha)^* \reduce C(\alpha^*) \\
  & \vdash \delta_{s, t}^* \reduce \delta_{s, t} \\
  & \vdash (S_1 + S_2)^* \reduce S_1^* + S_2^* \\
  & \vdash (S_1 \times S_2)^* \reduce S_1^* \times S_2^* \\
  & \vdash (S^*)^* \reduce S \\
  & \vdash (B \cdot K)^* \reduce K^\dagger \cdot B^\dagger
\end{align*}

\textbf{Remark: } We use the symbol $C$ to denoted the complex scalar in the module theory $\Sigma_\mathcal{S}$.



\subsubsection*{\textsf{SCR-DOT}}
\begin{align*}
  & \vdash \mathbf{0}_\mathcal{B} \cdot K \reduce C(0) \\
  & \vdash B \cdot \mathbf{0}_\mathcal{K} \reduce C(0) \\
  & \vdash (S.B) \cdot K \reduce S \times (B \cdot K) \\
  & \vdash B \cdot (S.K) \reduce S \times (B \cdot K) \\
  & \vdash (B_1 + B_2) \cdot K \reduce B_1 \cdot K + B_2 \cdot K \\
  & \vdash B \cdot (K_1 + K_2) \reduce B \cdot K_1 + B \cdot K_2 \\
  & \vdash \bra{s} \cdot \ket{t} \reduce \delta_{s, t} \\
\end{align*}

\begin{align*}
  & \vdash (B_1 \otimes B_2) \cdot \ket{t} \reduce (B_1 \cdot \ket{\fst\ t}) \times (B_2 \cdot \ket{\snd\ t}) \\
  & \vdash \bra{t} \cdot (K_1 \otimes K_2) \reduce (\bra{\fst\ t} \cdot K_1) \times (\bra{\snd\ t} \cdot K_2) \\
  & \vdash (B_1 \otimes B_2) \cdot (K_1 \otimes K_2) \reduce (B_1 \cdot K_1) \times (B_2 \cdot K_2)
\end{align*}

\textbf{Remark: } The difficulty here comes from Hilbert space structure. The intuition is that, we decompose the multiplication (inner product) when at least one side is explicitly in tensor product form.

\textbf{Remark:} Notice that we don't consider $\vdash (S.B) \cdot K \reduce (S^*).(B \cdot K)$. Inner product is linear (not conjugate linear) on $B$, because $B$ is already in the dual space.

\subsubsection*{\textsf{SCR-SORT}}
\begin{align*}
  & \vdash (B \cdot O) \cdot K \reduce B \cdot (O \cdot K) \\
  & \vdash \bra{s} \cdot ((O_1 \otimes O_2) \cdot K) \reduce ((\bra{\fst\ s} \cdot O_1) \otimes (\bra{\snd\ t} \cdot O_2)) \cdot K \\
  & \vdash (B_1 \otimes B_2) \cdot ((O_1 \otimes O_2) \cdot K) \reduce ((B_1 \cdot O_1) \otimes (B_2 \cdot O_2)) \cdot K \\
\end{align*}


\textbf{Remark: } The first rule sorts the multiplication to the right, which breaks the symmetry of ket and bra. The remaining three rules are for completion.

\subsubsection*{\textsf{KET-ADJ}}
\begin{align*}
  & \vdash \textbf{0}_\mathcal{B}^\dagger \reduce \textbf{0}_\mathcal{K} \\
  & \vdash \bra{t}^\dagger \reduce \ket{t}\\
  & \vdash (K^\dagger)^\dagger \reduce K \\
  & \vdash (S.B)^\dagger \reduce S^*.(B^\dagger) \\
  & \vdash (B_1 + B_2)^\dagger \reduce B_1^\dagger + B_2^\dagger\\
  & \vdash (B \cdot O)^\dagger \reduce O^\dagger \cdot B^\dagger \\
  & \vdash (B_1 \otimes B_2)^\dagger \reduce B_1^\dagger \otimes B_2^\dagger
\end{align*}

\subsubsection*{\textsf{KET-SCAL}}
\begin{align*}
  & \vdash C(0).K \reduce \textbf{0}_{\mathcal{K}}\\
  & \vdash C(1).K \reduce K \\
  & \vdash S.\textbf{0}_\mathcal{K} \reduce \textbf{0}_\mathcal{K} \\
  & \vdash S_1.(S_2.K) \reduce (S_1 \times S_2).K \\
  & \vdash S.(K_1 + K_2) \reduce S.K_1 + S.K_2
\end{align*}

\subsubsection*{\textsf{KET-ADD}}
\begin{align*}
  & \vdash K + \textbf{0}_\mathcal{K} \reduce K \\
  & \vdash K + K \reduce C(1 + 1).K \\
  & \vdash S.K + K \reduce (S + C(1)).K \\
  & \vdash S_1.K + S_2.K \reduce (S_1 + S_2).K
\end{align*}

\subsubsection*{\textsf{KET-MUL}}
\begin{align*}
  & \vdash \textbf{0}_\mathcal{O} \cdot K \reduce \textbf{0}_\mathcal{K} \\
  & \vdash O \cdot \mathbf{0}_{\mathcal{K}} \reduce \mathbf{0}_{\mathcal{K}} \\
  & \vdash \textbf{1}_\mathcal{O} \cdot K \reduce K \\
  & \vdash (S.O) \cdot K \reduce S.(O \cdot K) \\
  & \vdash O \cdot (S.K) \reduce S.(O \cdot K) \\
  & \vdash (O_1 + O_2) \cdot K \reduce O_1 \cdot K + O_2 \cdot K \\
  & \vdash O \cdot (K_1 + K_2) \reduce O \cdot K_1 + O \cdot K_2 \\
  & \textcolor{red}{\vdash (K_1 \otimes B) \cdot K_2 \reduce (B \cdot K_2).K_1} \\
  & \textcolor{red}{\vdash (O_1 \cdot O_2) \cdot K \reduce O_1 \cdot (O_2 \cdot K)} \\
  & \textcolor{red}{\vdash (O_1 \otimes O_2) \cdot ((O_1' \otimes O_2') \cdot K) \reduce ((O_1 \cdot O_1') \otimes (O_2 \cdot O_2')) \cdot K} \\
  & \vdash (O_1 \otimes O_2) \cdot \ket{t} \reduce (O_1 \cdot \ket{\fst\ t}) \otimes (O_2 \cdot \ket{\snd\ t}) \\
  & \vdash (O_1 \otimes O_2) \cdot (K_1 \otimes K_2) \reduce (O_1 \cdot K_1) \otimes (O_2 \cdot K_2)
\end{align*}

\textbf{Remark: } Again, the difficulty comes from space structure. The intuition for reductions is also the same: decompose the multiplication when at least one side is explicitly in tensor product form.


\subsubsection*{\textsf{KET-TSR}}
\begin{align*}
  & \vdash \mathbf{0}_\mathcal{K} \otimes K \reduce \mathbf{0}_\mathcal{K} \\
  & \vdash K \otimes \mathbf{0}_\mathcal{K} \reduce \mathbf{0}_\mathcal{K} \\
  & \vdash \ket{s} \otimes \ket{t}\reduce\ket{(s, t)} \\
  & \vdash (S.K_1) \otimes K_2 \reduce S.(K_1 \otimes K_2) \\
  & \vdash K_1 \otimes (S.K_2) \reduce S.(K_1 \otimes K_2) \\
  & \vdash (K_1 + K_2) \otimes K_3 \reduce K_1 \otimes K_3 + K_2 \otimes K_3 \\
  & \vdash K_1 \otimes (K_2 + K_3) \reduce K_1 \otimes K_2 + K_1 \otimes K_3
\end{align*}

\textbf{Remark: } The rules for bra are symmetric to the rules for ket. Only the correspondence of rules in red are different:

\begin{align*}
  & \textcolor{red}{\vdash B_1 \cdot (K \otimes B_2) \reduce (B_1 \cdot K).B_2} \\
  & \textcolor{red}{\vdash B \cdot (O_1 \cdot O_2) \reduce (B \cdot O_1) \cdot O_2} \\
  & \textcolor{red}{\vdash (B \cdot (O_1 \otimes O_2)) \cdot (O_1' \otimes O_2') \reduce B \cdot ((O_1 \cdot O_1') \otimes (O_2 \cdot O_2'))}
\end{align*}

\subsubsection*{\textsf{OPT-OUTER}}
\begin{align*}
  & \vdash \mathbf{0}_\mathcal{K} \otimes B \reduce \mathbf{0}_\mathcal{O} \\
  & \vdash K \otimes \mathbf{0}_\mathcal{B} \reduce \mathbf{0}_\mathcal{O} \\
  & \vdash (S.K) \otimes B \reduce S.(K \otimes B) \\
  & \vdash K \otimes (S.B) \reduce S.(K \otimes B) \\
  & \vdash (K_1 + K_2) \otimes B \reduce K_1 \otimes B + K_2 \otimes B \\
  & \vdash K \otimes (B_1 + B_2) \reduce K \otimes B_1 + K \otimes B_2
\end{align*}


\subsubsection*{\textsf{OPT-ADJ}}
\begin{align*}
  & \vdash \textbf{0}_\mathcal{O}^\dagger \reduce \textbf{0}_\mathcal{O} \\
  & \vdash \textbf{1}_\mathcal{O}^\dagger \reduce \textbf{1}_\mathcal{O} \\
  & \vdash (K \otimes B)^\dagger \reduce B^\dagger \otimes K^\dagger \\
  & \vdash (O^\dagger)^\dagger \reduce O \\
  & \vdash (S.O)^\dagger \reduce S^*.(O^\dagger) \\
  & \vdash (O_1 + O_2)^\dagger \reduce O_1^\dagger + O_2^\dagger\\
  & \vdash (O_1 \cdot O_2)^\dagger \reduce O_2^\dagger \cdot O_1^\dagger \\
  & \vdash (O_1 \otimes O_2)^\dagger \reduce O_1^\dagger \otimes O_2^\dagger
\end{align*}

\subsubsection*{\textsf{OPT-SCAL}}
\begin{align*}
  & \vdash C(0).O \reduce \mathbf{0}_\mathcal{O} \\
  & \vdash C(1).O \reduce O \\
  & \vdash S.\textbf{0}_\mathcal{O} \reduce \textbf{0}_\mathcal{O} \\
  & \vdash S_1.(S_2.O) \reduce (S_1 \times S_2).O \\
  & \vdash S.(O_1 + O_2) \reduce S.O_1 + S.O_2
\end{align*}

\subsubsection*{\textsf{OPT-ADD}}
\begin{align*}
  & \vdash O + \mathbf{0}_\mathcal{O} \reduce O \\
  & \vdash O + O \reduce C(1 + 1).O \\
  & \vdash S.O + O \reduce (S + C(1)).O \\
  & \vdash S_1.O + S_2.O \reduce (S_1 + S_2).O
\end{align*}

\subsubsection*{\textsf{OPT-MUL}}
\begin{align*}
  & \vdash \mathbf{0}_\mathcal{O} \cdot O \reduce \mathbf{0}_\mathcal{O} \\
  & \vdash O \cdot \mathbf{0}_\mathcal{O} \reduce \mathbf{0}_\mathcal{O} \\
  & \vdash \mathbf{1}_\mathcal{O} \cdot O \reduce O \\
  & \vdash O \cdot \mathbf{1}_\mathcal{O} \reduce O \\
  & \vdash (K \otimes B) \cdot O \reduce K \otimes (B \cdot O)\\
  & \vdash O \cdot (K \otimes B) \reduce (O \cdot K) \otimes B\\
  & \vdash (S.O_1) \cdot O_2 \reduce S.(O_1 \cdot O_2) \\
  & \vdash O_1 \cdot (S.O_2) \reduce S.(O_1 \cdot O_2) \\
  & \vdash (O_1 + O_2) \cdot O_3 \reduce O_1 \cdot O_3 + O_2 \cdot O_3 \\
  & \vdash O_1 \cdot (O_2 + O_3) \reduce O_1 \cdot O_2 + O_1 \cdot O_3 \\
  & \vdash (O_1 \cdot O_2) \cdot O_3 \reduce O_1 \cdot (O_2 \cdot O_3) \\
  & \vdash (O_1 \otimes O_2) \cdot (O_1' \otimes O_2') \reduce (O_1 \cdot O_1') \otimes (O_2 \cdot O_2') \\
  & \vdash (O_1 \otimes O_2) \cdot ((O_1' \otimes O_2') \cdot O_3) \reduce ((O_1 \cdot O_1') \otimes (O_2 \cdot O_2')) \cdot O_3
\end{align*}


\subsubsection*{\textsf{OPT-TSR}}
\begin{align*}
  & \vdash \mathbf{0}_\mathcal{O} \otimes O \reduce \mathbf{0}_\mathcal{O} \\
  & \vdash O \otimes \mathbf{0}_\mathcal{O} \reduce \mathbf{0}_\mathcal{O} \\
  & \vdash (K_1 \otimes B_1) \otimes (K_2 \otimes B_2) \reduce (K_1 \otimes K_2) \otimes (B_1 \otimes B_2) \\
  & \vdash (S.O_1) \otimes O_2 \reduce S.(O_1 \otimes O_2) \\
  & \vdash O_1 \otimes (S.O_2) \reduce S.(O_1 \otimes O_2) \\
  & \vdash (O_1 + O_2) \otimes O_3 \reduce O_1 \otimes O_3 + O_2 \otimes O_3 \\
  & \vdash O_1 \otimes (O_2 + O_3) \reduce O_1 \otimes O_2 + O_1 \otimes O_3
\end{align*}


\section{Typed Dirac Notation}

Now we build a type system based on the untyped Dirac notation. With the typing information, we are able to achieve the polymorphism of the universal application symbol, which is close to how Dirac notation is dealt with in practice.

\subsubsection*{Polymorphism of Universal Application}

I believe the essence of Dirac notation is the polymorphism of universal application, which means that the same symbol is overloaded as different funtions based on the type of operands. We often use a universal application binary symbol (denoted as $\circ$) to concatenate subterms. For example, 
$$
\bra{a} \circ \ket{b} \circ \bra{c} \circ \ket{d} = \< a | b \> \< c | d \>.
$$
This term has no ambiguity because universal application is expected to be associative. And $\circ$ is overloaded differently based on how we associate the calculation. For example,
$$
(\bra{a} \circ \ket{b}) \circ (\bra{c} \circ \ket{d}) = \< a | b \> \times \< c | d \>
$$
$$
\bra{a} \circ (\ket{b} \circ \bra{c}) \circ \ket{d} = \< a | \cdot | b \>\< c | \cdot | d \>
$$

The complete list of overloading is given by the table:

\begin{center}
  \begin{tabular}{|c|c|c|c|c|}
    \hline
    $X \circ Y$ & $Y \in \mathcal{S}$ & $Y\in \mathcal{K}$ & $Y \in \mathcal{B}$ & $Y \in \mathcal{O}$ \\
    \hline
    $X \in \mathcal{S}$ & $S_X \times S_Y$ & $S_X.K_Y$ & $S_X.B_Y$ & $S_X.O_Y$ \\
    \hline
    $X \in \mathcal{K}$ & $S_Y.K_X$ & $K_X \otimes K_Y$ & $ K_X \otimes B_Y$ &  \\
    \hline
    $X \in \mathcal{B}$ & $S_Y.B_X$ & $B_X \cdot K_Y$ & $B_X \otimes B_Y$ & $B_X \cdot O_Y$ \\
    \hline
    $X \in \mathcal{O}$ & $S_Y.O_X$ & $O_X \cdot K_Y$ &  & $O_X \cdot O_Y$ \\
    \hline
  \end{tabular}
\end{center}


A major topic of this work is to prove the associativity of the universal application symbol constructed in the TRS.

\subsubsection*{Polymorphism of otimes and cdot}
Similar to the universal application symbol $\circ$, we also use $A \otimes B$ and $A \cdot B$ in a polymorphic way. This is also encoded in the \texttt{CiME} script.



\subsubsection*{Type Definition}

\begin{definition}[Types]
  The type for basis is defined by
  \begin{align*}
    \tau ::= T\ |\ (\tau * \tau),
  \end{align*}
  Here $T$ is the type for atomic bases.
  The type for scalar, ket, bra and operator are defined by $\mathcal{S}$, $\mathcal{K}(\tau)$, $\mathcal{B}(\tau)$ and $\mathcal{O}(\tau, \sigma)$, respectively.
\end{definition}

\subsection{typing rules}
  A typing assumption has the form $x : \tau$, meaning variable $x$ has the type $\tau$. A typing context $\Gamma$ consists of typing assumptions and each variable appears only once.

  A typing judgement $\vdash e : \sigma$ indicates that $e$ is a term of type $\sigma$ in context $\Gamma$. The well-typed terms are defined by the following rules.

\subsubsection*{Typing of Basis}
  \begin{gather*}
    \frac{x : \sigma \in \Gamma}{\vdash x : \sigma}
    \qquad 
    \vdash b : T\\
    \\
    \frac{\vdash t_1 : \tau \qquad \vdash t_2 : \sigma}{\vdash (t_1, t_2) : ( \tau * \sigma )} \\
    \\
    \frac{\vdash t : ( \tau * \sigma )}{\vdash \fst\ t : \tau}
    \qquad
    \frac{\vdash t : ( \tau * \sigma )}{\vdash \snd\ t : \sigma}
  \end{gather*}

\subsubsection*{Typing of Scalar}
  \begin{gather*}
    \frac{x : \mathcal{S} \in \Gamma}{\vdash x : \mathcal{S}}
    \qquad 
    \vdash C(\alpha) : \mathcal{S}
    \qquad
    \frac{\vdash s : \tau \qquad \vdash t : \tau}{\vdash \delta_{s, t} : \mathcal{S}} \\
    \\
    \frac{\vdash S_1 : \mathcal{S} \qquad \vdash S_2 : \mathcal{S}}{\vdash S_1 + S_2 : \mathcal{S}}
    \qquad
    \frac{\vdash S_1 : \mathcal{S} \qquad \vdash S_2 : \mathcal{S}}{\vdash S_1 \times S_2 : \mathcal{S}} \\
    \\
    \frac{\vdash S : \mathcal{S}}{\vdash S^* : \mathcal{S}} \\
    \\
    \frac{\vdash B : \mathcal{B}(\tau) \qquad \vdash K : \mathcal{K}(\tau)}{\vdash B \cdot K : \mathcal{S}}
  \end{gather*}


\subsubsection*{Typing of Ket}
  \begin{gather*}
    \frac{x : \mathcal{K}(\tau) \in \Gamma}{\vdash x : \mathcal{K}(\tau)}
    \qquad
    \vdash \zeroK{\tau} : \mathcal{K}(\tau)
    \qquad
    \frac{\vdash t : \tau}{\vdash \ket{t} : \mathcal{K}(\tau)} \\
    \\
    \frac{\vdash B : \mathcal{B}(\tau)}{\vdash B^\dagger : \mathcal{K}(\tau)}
    \qquad
    \frac{\vdash S : \mathcal{S} \qquad \vdash K : \mathcal{K}(\tau)}{\vdash S.K : \mathcal{K}(\tau)} \\
    \\
    \frac{\vdash K_1 : \mathcal{K}(\tau) \qquad \vdash K_2 : \mathcal{K}(\tau)}{\vdash K_1 + K_2 : \mathcal{K}(\tau)} \\
    \\
    \frac{\vdash O : \mathcal{O}(\tau, \sigma) \qquad \vdash K : \mathcal{K}(\sigma)}{\vdash O \cdot K : \mathcal{K}(\tau)} \\
    \\
    \frac{\vdash K_1 : \mathcal{K}(\tau_1) \qquad \vdash K_2 : \mathcal{K}(\tau_2)}{\vdash K_1 \otimes K_2 : \mathcal{K}(\tau_1 * \tau_2)}
  \end{gather*}


\subsubsection*{Typing of Bra}
  \begin{gather*}
    \frac{x : \mathcal{B}(\tau) \in \Gamma}{\vdash x : \mathcal{B}(\tau)}
    \qquad
    \vdash \zeroB{\tau} : \mathcal{B}(\tau)
    \qquad
    \frac{\vdash t : \tau}{\vdash \bra{t} : \mathcal{B}(\tau)} \\
    \\
    \frac{\vdash K : \mathcal{K}(\tau)}{\vdash K^\dagger : \mathcal{B}(\tau)}
    \qquad
    \frac{\vdash S : \mathcal{S} \qquad \vdash B : \mathcal{B}(\tau)}{\vdash S.B : \mathcal{B}(\tau)} \\
    \\
    \frac{\vdash B_1 : \mathcal{B}(\tau) \qquad \vdash B_2 : \mathcal{B}(\tau)}{\vdash B_1 + B_2 : \mathcal{B}(\tau)} \\
    \\
    \frac{\vdash B : \mathcal{B}(\tau) \qquad \vdash O : \mathcal{O}(\tau, \sigma)}{\vdash B \cdot O : \mathcal{B}(\sigma)} \\
    \\
    \frac{\vdash B_1 : \mathcal{B}(\tau_1) \qquad \vdash B_2 : \mathcal{B}(\tau_2)}{\vdash B_1 \otimes B_2 : \mathcal{B}(\tau_1 * \tau_2)}
  \end{gather*}


\subsubsection*{Typing of Operator}
  \begin{gather*}
  \frac{x : \mathcal{O}(\tau, \sigma) \in \Gamma}{\vdash x : \mathcal{O}(\tau, \sigma)}
  \qquad
  \vdash \zeroO{\tau, \sigma} : \mathcal{O}(\tau, \sigma) 
  \qquad
  \vdash \textbf{1}_{\mathcal{O}(\tau)} : \mathcal{O}(\tau, \tau) 
  \qquad
  \frac{\vdash K : \mathcal{K}(\tau) \qquad \vdash B : \mathcal{B}(\sigma)}{\vdash K \otimes B : \mathcal{O}(\tau, \sigma)} \\
  \\
  \frac{\vdash O : \mathcal{O}(\tau, \sigma)}{\vdash O^\dagger : \mathcal{O}(\sigma, \tau)}
  \qquad
  \frac{\vdash S : \mathcal{S} \qquad \vdash O : \mathcal{O}(\tau, \sigma)}{\vdash S.O : \mathcal{O}(\tau, \sigma)} \\
  \\
  \frac{\vdash O_1 : \mathcal{O}(\tau, \sigma) \qquad \vdash O_2 : \mathcal{O}(\tau, \sigma)}{\vdash O_1 + O_2 : \mathcal{O}(\tau, \sigma)} \\
  \\
  \frac{\vdash O_1 : \mathcal{O}(\tau, \sigma) \qquad \vdash O_2 : \mathcal{O}(\sigma, \rho)}{\vdash O_1 \cdot O_2 : \mathcal{O}(\tau, \rho)} \\
  \\
  \frac{\vdash O_1 : \mathcal{O}(\tau_1, \sigma_1) \qquad \vdash O_2 : \mathcal{O}(\tau_2, \sigma_2)}{\vdash O_1 \cdot O_2 : \mathcal{O}(\tau_1 * \tau_2, \rho_1 * \rho_2)}
\end{gather*}

\textbf{Remark: } The type system is transformed and encoded in the simplest TRS. All the typing rules are treated as reduction rules.


\section{Termination}

Termination tool: see \url{https://link.springer.com/chapter/10.1007/978-3-030-17502-3_10}

May be we can try \texttt{MU-TERM}.


\section{Confluence}

We use \texttt{CiME2} to check the local confluence of the TRS of typed Dirac notation automatically. Because our TRS contains modulo theories and AC-symbols, we need to apply some the techniques:

\begin{itemize}
  \item consider a smallest instance of the complex scalar rewrite system and utilize the avatar lemma, and
  \item consider an extended system due to the AC-symbols.
\end{itemize}

The whole procedure is very similar to that of Lineal.

\subsection{Confluence modulo Theory and the Avatar Lemma}

First we introduce some concepts about modularity and the avatar lemma.

\begin{definition}[Subsumption]
  A terminating and confluent relation $S$ subsumes a relation $S_0$ if whenever $t \to_{S_0} u$, $t$ and $u$ have the same $S$-normal form.
\end{definition}

\begin{definition}[Commuting relations]
  Two relations $X$ and $Y$ are said to be commuting if whenever $t \to_X u$ and $t \to_Y v$, there exists a term $w$ such that $u \to_Y w$ and $v \to_X w$.
\end{definition}

\begin{proposition}[The avatar lemma] \cite{Arrighi2005} Let $X$, $S$ and $S_0$ be three relations defined on a set such that:
  \begin{itemize}
    \item $S$ is terminating and confluent;
    \item $S$ subsumes $S_0$;
    \item $S_0 \cup X$ is locally confluent;
    \item $X$ commutes with $S^*$.
  \end{itemize}
  Then, the relation $S \cup X$ is locally confluent.
\end{proposition}

We now present a smallest instantiation $\mathfrak{S}_0$ of a complext scalar rewrite system. 

\begin{definition}[The rewrite system $\mathfrak{S}_0$]
  The system $\mathfrak{S}_0$ is defined by the following rules:
  \begin{gather*}
    0 + \alpha \reduce \alpha\\
    0 \times \alpha \reduce 0\\
    1 \times \alpha \reduce \alpha\\
    \alpha \times (\beta + \gamma) \reduce \alpha \times \beta + \alpha \times \gamma\\
    0^* \reduce 0 \\
    1^* \reduce 1 \\
    (\alpha + \beta)^* \reduce \alpha^* + \beta^*\\
    (\alpha \times \beta)^* \reduce \alpha^* \times \beta^*\\
    (\alpha^*)^* \reduce \alpha
  \end{gather*}
  where $+$ and $\times$ are AC-symbols.
\end{definition}


\subsection{AC-rewriting and Extension Rules}
If a TRS $R$ contains AC-symbols, checking the critical pairs of $R$ is not enough to ensure the local confluence of $R$. This is because the LHS of rules can match the term unlocally. For example:
$$
(K_0 + K_1) + K_0 \reduce C(1 + 1).K_0 + K_1
$$
by the rule $\vdash K + K \reduce C(1 + 1).K$. We need to consider an extended system, as indicated by the following definition.

\begin{definition}[The extension rules]
  Let $X$ be a AC-rewrite system with AC symbols $f_1, \cdots, f_n$. We define the AC-rewrite system $X_{ext}$ as containing the same AC symbols as $X$, the same rules as $X$, plus the rule $f_i(t, x) \to f_i(u, x)$ for each rule $t \to u$ of $X$ where the head symbol of $t$ is $f_i$.
\end{definition}

\begin{proposition}
  The globally AC reduction relation of system $X$ is confluent if and only if the locally AC reduction relation of $X_{ext}$ is confluent.
\end{proposition}

And we can check the local confluence of locally AC reduction of $X_{ext}$ by calculating the critical pairs.

\begin{proposition}[$\mathfrak{S}_{0ext}$]
  The system $\mathfrak{S}_{0ext}$ is formed by the rules in $S_0$ and the rule
  \begin{align*}
    & (0 + \alpha) + \chi \reduce \alpha + \chi \\
    & (0 \times \alpha) \times \chi \reduce 0 \times \chi \\
    & (1 \times \alpha) \times \chi \reduce \alpha \times \chi \\
    & (\alpha \times (\beta + \gamma)) \times \chi \reduce (\alpha \times \beta + \alpha \times \gamma) \times \chi \\
  \end{align*}
\end{proposition}

\begin{proposition}
  The system $\mathfrak{D}_{ext}$ is formed by the rules in $\mathfrak{D}$ and the rule
  \begin{align*}
    & (C(0) + a) + x \reduce a + x \\
    & (C(a) + C(b)) + x \reduce C(a + b) + x \\
    & (S + S) + x \reduce (C(1 + 1) \times S) + x \\
    & ((C(a) \times S) + S) + x \reduce (C(a + 1) \times S) + x \\
    & ((C(a) \times S) + (C(b) \times S)) + x \reduce (C(a + b) \times S) + x \\
    \\
    & (C(0) \times a) \times x \reduce C(0) \times x \\
    & (C(1) \times a) \times x \reduce a \times x \\
    & (C(a) \times C(b)) \times x \reduce C(a \times b) \times x \\
    & (S_1 \times (S_2 + S_3)) \times x \reduce ((S_1 \times S_2) + (S_1 \times S_3)) \times x \\
    \\
    & (K + \mathbf{0}_\mathcal{K}) + x \reduce K + x \\
    & (K + K) + x \reduce C(1 + 1).K + x \\
    & (S.K + K) + x \reduce (S + 1).K + x \\
    & (S_1.K + S_2.K) + x \reduce (S_1 + S_2).K + x \\
    \\
    & \textrm{(same for bra)}\\
    \\
    & (O + \mathbf{0}_\mathcal{O}) + x \reduce O + x \\
    & (O + O) + x \reduce C(1 + 1).O + x \\
    & (S.O + O) + x \reduce (S + 1).O + x \\
    & (S_1.O + S_2.O) + x \reduce (S_1 + S_2).O + x
  \end{align*}
\end{proposition}

\begin{proposition}
  The system $\mathfrak{S}_{0ext} \cup \mathfrak{D}_{ext}$ is locally confluent.
\end{proposition}
\begin{proof}
  Checked by \texttt{CiME2}.
\end{proof}

\section{Checking by \texttt{CiME}}

We encoded the typed Dirac notation in a simple TRS and checked the confluence of the whole system. Here is a summary of the rules.


\begin{center}
  \begin{tabular}{c|c}
  \hline
  Type & Rule Number \\
  \hline
  type checking & 27 \\
  overloading polymorphic symbols & 22 \\
  complex scalar avatar & 9 \\
  Dirac notation & 141 \\
  AC-symbol extension rules & 25 \\
  \hline
  Total & 224 \\
  \hline
  \end{tabular}
\end{center}

And all the 3133 critical pairs are joinable.

\subsubsection*{About Reduandancy}
I also checked through a \texttt{Python} script that removing any of the reduction rule will lead to non-confluence or change of the equational theory. For example, I found that removing 
$$
\vdash (\fst\ e, \snd\ e)\reduce e
$$
or
$$
\vdash (K_1 \otimes B_1) \otimes (K_2 \otimes B_2) \reduce (K_1 \otimes K_2) \otimes (B_1 \otimes B_2)
$$
respectively will still lead to a confluence TRS, but the equivalence induced by the TRS will be be changed.




\section{Extension for Delta Operators}

In the backbone rewriting system, we don't attempt to reduce Delta operators $\delta_{s, t}$ to constants $0$ or $1$. This is because the complete reduction needs some semantic analysis and can be quite difficult. This section tries to find such a good extension.


To demonstrate the difficulty, we first consider the following example:
$$
\delta_{i, j} \times \delta_{i, k} = \delta_{i, j} \times \delta_{j, k}.
$$
This equality holds, but it is hard to detect merely by the syntax. In general, The equality and reduction of Delta operators need the semantic analysis, which is presented below.


\subsubsection*{DeltaEQ}
$$
\frac{(\bigwedge_i s_i =_\textsf{BASIS} t_i) \leftrightarrow (\bigwedge_i s_i' =_\textsf{BASIS} t_i') \textrm{ is valid}}{\prod_i \delta_{s_i, t_i} = \prod_i \delta_{s_i', t_i'}}
$$

\subsubsection*{\textsf{DELTA-COMPLETE}}

\begin{align*}
  & \textsc{(Delta1)} && 
  \frac{\bigwedge_i s_i =_\textsf{BASIS} t_i \textrm{ is valid}}{\vdash \prod_i \delta_{s_i, t_i} \reduce 1}
  \\
  \\
  & \textsc{(Delta0)} && 
  \frac{\bigwedge_i s_i =_\textsf{BASIS} t_i \textrm{ is not satisfiable}}{\vdash \prod_i \delta_{s_i, t_i} \reduce 0}
\end{align*}


In other words, the property of Delta operators is determined by the proposition.

\yx{We need to prove that the backbone system together with these rules are confluent.}

\subsection{Extension for Delta Operator (simple version)}
It's impractical to fully deicide the three conditions, espacially when the atomic basis $\mathfrak{B}$ is complicated. Therefore we present here a simpler extension to rewrite these Delta operators in common cases.

\subsubsection*{\textsf{DELTA*}}
\begin{align*}
  & \textsc{(Delta1)} && 
  \vdash \delta_{s, s} \reduce 1
  \\
  \\
  & \textsc{(Delta0)} &&
  \frac{s, t \text{ are different ground terms}}{\vdash \delta_{s, t} \reduce 0}
\end{align*}

\subsection{Extension for Delta Operator (SMT solver)}
We can use a SMT solver to check the conditions for the equality \textbf{DeltaEQ} and rules in \textsf{DELTA-COMPLETE}.

\yx{At least we should draw a line between what can be decided and what can't, about this Delta operator.}

\yx{How to deal with $\sum_i \delta_{i, j}$ then? -- It should be summing on the set that satisfies the proposition.}



\section{Dirac with Big-operator}
We extend the language of Dirac notation with the sort $\mathcal{S}_\tau$ for sets of type $\tau$, and the following syntax for terms:
$$
t ::= \sum_{x \in S} t
$$

Here $\sum_{x : \tau} t$ can be considered as a special abstraction, where $x$ is the bound variable for index with type $S$.

\begin{definition}[typing rule]
  The typing rule for the big operator is similar to the one for abstraction.

  $$
  \frac{\Gamma \vdash S : \mathcal{S}_\tau\qquad \Gamma::(x : \tau) \vdash e : \sigma}{\Gamma \vdash \sum_{x \in S} e : \sigma}
  $$
  
\end{definition}

\begin{definition}[The system Sum]
    \begin{align*}
        & \Gamma \vdash \sum_{x \in S} \mathbf{0}_{\sigma, \rho} \ \triangleright\ \mathbf{0}_{\sigma, \rho} \\
        & \Gamma \vdash e \otimes \sum_{x \in S} u \ \triangleright\ \sum_{x \in S} e \otimes u \\
        &\Gamma \vdash e\cdot \sum_{x \in S} v \ \triangleright \sum_{x \in S} (e\cdot v)
        \qquad 
        \Gamma \vdash (\sum_{x \in S} v) \cdot e\ \triangleright \sum_{x \in S} (v \cdot e)\\        
        & \Gamma \vdash \sum_{x \in S} u + \sum_{x \in S} v  \ \triangleright\ \sum_{x \in S} (u + v) \\
        \tag{**}
        & \sum_{x \in S} \sum_{y \in S'} u = \sum_{y \in S'} \sum_{x \in S} u
    \end{align*}
(**)\ Requires that $\sigma$ is not dependent on $x$, which is always the case in the simply typed situation.

And sum is not considered as a base vector.
\end{definition}

\yx{A serious problem: How to deal with the summation over a set of index? And how can we decide
$$
\sum_{i \in \mathbb{B}} \ket{i} = \ket{0} + \ket{1}
$$}

\yx{Maybe we can consider the set to be expressed in the form of the enumeration by a list or array.
$$
\Gamma \vdash \sum_{i \in \{i_0, \dots, i_n\}} e \ \triangleright\ e[i_0/i] + \cdots + e[i_n/i]
$$
}